{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import pandas as pd\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "import seaborn as sns\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib import colormaps\n",
    "import folium"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = np.load('data/dcrnn_denhaag_S36_DR2_RNN2_predictions.npz')\n",
    "data1 = np.load('data/dcrnn_denhaag_S36_predictions.npz')\n",
    "\n",
    "with open('data/sensor_graph/graph_sensor_ids.txt', 'r') as file:\n",
    "    content = file.read()\n",
    "    native_indices = [int(index.strip()) for index in content.split(',')]\n",
    "\n",
    "\n",
    "# Load the data\n",
    "data_path = 'data/DH.h5'\n",
    "df = pd.read_hdf(data_path)\n",
    "\n",
    "# Extract the timestamps for the last 572 example (Test set)\n",
    "timestamps = df.index[-572:]\n",
    "timestamps_str = [ts.strftime('%H-%M\\n%d/%m/%Y') if ts.strftime('%H-%M') == '00-00' or ts.strftime('%H-%M') == '12-00' else ts.strftime('%H-%M') for ts in timestamps]\n",
    "samples_per_day=96\n",
    "samples_per_hour = samples_per_day // 24\n",
    "\n",
    "# Extract the ground truth and predictions for the last 572 examples (Test set)\n",
    "prediction2 = data2['prediction']\n",
    "prediction1 = data1['prediction']\n",
    "truth = data1['truth']\n",
    "\n",
    "horizon = truth.shape[0]\n",
    "\n",
    "# Define the horizon labels for 15 min intervals in the format [15min, 30min, 45min, 1h, 1h15min, 1h30min, 1h45min, 2h]:\n",
    "horizon_labels = ['15min', '30min', '45min', '1h', '1h15min', '1h30min', '1h45min', '2h']\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the error metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def errors(truth, prediction, n, sensor):\n",
    "    ae = []\n",
    "    se = []\n",
    "    pe = []\n",
    "    # Iterate over the time\n",
    "    avg_truth = np.abs(np.mean(truth[n,:,sensor]))\n",
    "    for i in range(truth.shape[1]): \n",
    "        # Append absolute error\n",
    "        ae.append(np.abs(truth[n,i,sensor] - prediction[n,i,sensor]))\n",
    "        # Append squared error\n",
    "        se.append(np.square(truth[n,i,sensor] - prediction[n,i,sensor]))\n",
    "        # Append absolute percentage error\n",
    "        pe.append(np.abs((truth[n,i,sensor] - prediction[n,i,sensor]) / truth[n,i,sensor])*100 if truth[n,i,sensor] > 0 else np.abs((truth[n,i,sensor] - prediction[n,i,sensor]) / avg_truth)*100)\n",
    "    mae = np.mean(ae)\n",
    "    mae_std = np.std(ae)\n",
    "    rmse = np.sqrt(np.mean(se))\n",
    "    rmse_std = np.sqrt(np.std(se))\n",
    "    mape = np.mean(pe)\n",
    "    mape_std = np.std(pe)\n",
    "    \n",
    "    return mae, mae_std, rmse, rmse_std, mape, mape_std"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute errors for each sensor and each horizon for both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: NoConv\n",
    "errorNoConv = np.empty((horizon, truth.shape[2],6))\n",
    "\n",
    "for n in range(horizon):\n",
    "    for s in range(truth.shape[2]):\n",
    "        errorNoConv[n,s,0], errorNoConv[n,s,1],errorNoConv[n,s,2], errorNoConv[n,s,3], errorNoConv[n,s,4], errorNoConv[n,s,5] = errors(truth, prediction1, n, s)\n",
    "\n",
    "# Error is a 3D array with shape (horizon, num_sensors, 6)\n",
    "average_error_NoConv = np.empty((horizon,3,2))\n",
    "\n",
    "average_error_NoConv[:,0,0] = np.mean(errorNoConv[:,:,0], axis=1)  # MAE\n",
    "average_error_NoConv[:,0,1] = np.std(errorNoConv[:,:,0], axis=1)   # MAE std\n",
    "average_error_NoConv[:,1,0] = np.mean(errorNoConv[:,:,2], axis=1)  # RMSE\n",
    "average_error_NoConv[:,1,1] = np.std(errorNoConv[:,:,2], axis=1)   # RMSE std\n",
    "average_error_NoConv[:,2,0] = np.mean(errorNoConv[:,:,4], axis=1)  # MAPE\n",
    "average_error_NoConv[:,2,1] = np.std(errorNoConv[:,:,4], axis=1)   # MAPE std\n",
    "\n",
    "# Model 2: DCRNN\n",
    "errorDCRNN = np.empty((horizon, truth.shape[2],6))\n",
    "\n",
    "for n in range(horizon):\n",
    "    for s in range(truth.shape[2]):\n",
    "        errorDCRNN[n,s,0], errorDCRNN[n,s,1], errorDCRNN[n,s,2], errorDCRNN[n,s,3], errorDCRNN[n,s,4], errorDCRNN[n,s,5] = errors(truth, prediction2, n, s)\n",
    "        \n",
    "#  Error matrix is of shape (horizon, num_sensors, 6)\n",
    "average_error_DCRNN = np.empty((horizon, 3, 2))  # Initialize average_error array\n",
    "\n",
    "\n",
    "# Compute means and standard deviations of error metrics \n",
    "average_error_DCRNN[:,0,0] = np.mean(errorDCRNN[:,:,0], axis=1)  # MAE\n",
    "average_error_DCRNN[:,0,1] = np.std(errorDCRNN[:,:,0], axis=1)  # MAE_std\n",
    "average_error_DCRNN[:,1,0] = np.mean(errorDCRNN[:,:,2], axis=1)  # RMSE\n",
    "average_error_DCRNN[:,1,1] = np.std(errorDCRNN[:,:,2], axis=1)  # RMSE_std\n",
    "average_error_DCRNN[:,2,0] = np.mean(errorDCRNN[:,:,4], axis=1)  # MAPE\n",
    "average_error_DCRNN[:,2,1] = np.std(errorDCRNN[:,:,4], axis=1) # MAPE_std\n",
    "\n",
    "# Extract MAE, RMSE and MAPE values from average_error arrays\n",
    "mae_values_DCRNN = errorDCRNN[:,:,0].T  # MAE values are at index 0\n",
    "mae_values_NoConv = errorNoConv[:,:,0].T  # MAE values are at index 0\n",
    "rmse_values_DCRNN = errorDCRNN[:,:,2].T  # RMSE values are at index 2\n",
    "rmse_values_NoConv = errorNoConv[:,:,2].T  # RMSE values are at index 2\n",
    "mape_values_DCRNN = errorDCRNN[:,:,4].T  # MAPE values are at index 4\n",
    "mape_values_NoConv = errorNoConv[:,:,4].T  # MAPE values are at index 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the average MAE, RMSE and MAPE values with their standard deviations for each horizon:\n",
    "print('Average MAE values for each horizon:')\n",
    "print('NoConv: ', [\"{:.1f} (±{:.1f})\".format(mean, std) for mean, std in zip(average_error_NoConv[:,0,0], average_error_NoConv[:,0,1])])\n",
    "print('DCRNN: ', [\"{:.1f} (±{:.1f})\".format(mean, std) for mean, std in zip(average_error_DCRNN[:,0,0], average_error_DCRNN[:,0,1])])\n",
    "print('\\nAverage RMSE values for each horizon:')\n",
    "print('NoConv: ', [\"{:.1f} (±{:.1f})\".format(mean, std) for mean, std in zip(average_error_NoConv[:,1,0], average_error_NoConv[:,1,1])])\n",
    "print('DCRNN: ', [\"{:.1f} (±{:.1f})\".format(mean, std) for mean, std in zip(average_error_DCRNN[:,1,0], average_error_DCRNN[:,1,1])])\n",
    "print('\\nAverage MAPE values for each horizon:')\n",
    "print('NoConv: ', [\"{:.1f}% (±{:.1f}%)\".format(mean, std) for mean, std in zip(average_error_NoConv[:,2,0], average_error_NoConv[:,2,1])])\n",
    "print('DCRNN: ', [\"{:.1f}% (±{:.1f}%)\".format(mean, std) for mean, std in zip(average_error_DCRNN[:,2,0], average_error_DCRNN[:,2,1])])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the error metrics as a function of the prediction horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the error metrics as a function of the prediction horizon\n",
    "\n",
    "# MAE\n",
    "fig, ax = plt.subplots(3,1, figsize=(10,10))\n",
    "ax[0].plot(average_error_NoConv[:,0,0], label='MAE_NoConv', color='gray')\n",
    "ax[0].fill_between(np.arange(horizon), average_error_NoConv[:,0,0] - average_error_NoConv[:,0,1], average_error_NoConv[:,0,0] + average_error_NoConv[:,0,1], alpha=0.2, color='gray')\n",
    "ax[0].plot(average_error_DCRNN[:,0,0], label='MAE_DCRNN')\n",
    "ax[0].fill_between(np.arange(horizon), average_error_DCRNN[:,0,0] - average_error_DCRNN[:,0,1], average_error_DCRNN[:,0,0] + average_error_DCRNN[:,0,1], alpha=0.3)\n",
    "ax[0].set_ylabel('MAE')\n",
    "ax[0].set_xlabel('Prediction Horizon')\n",
    "ax[0].set_xticks(np.arange(0,horizon))\n",
    "ax[0].set_xticklabels(horizon_labels)\n",
    "# ax[0].set_ylim(0,20)\n",
    "ax[0].legend()\n",
    "ax[0].set_title('Mean Absolute Error')\n",
    "\n",
    "# RMSE\n",
    "ax[1].plot(average_error_NoConv[:,1,0], label='RMSE_NoConv', color='gray')\n",
    "ax[1].fill_between(np.arange(horizon), average_error_NoConv[:,1,0] - average_error_NoConv[:,1,1], average_error_NoConv[:,1,0] + average_error_NoConv[:,1,1], alpha=0.2, color='gray')\n",
    "ax[1].plot(average_error_DCRNN[:,1,0], label='RMSE_DCRNN')\n",
    "ax[1].fill_between(np.arange(horizon), average_error_DCRNN[:,1,0] - average_error_DCRNN[:,1,1], average_error_DCRNN[:,1,0] + average_error_DCRNN[:,1,1], alpha=0.3)\n",
    "ax[1].set_ylabel('RMSE')\n",
    "ax[1].set_xlabel('Prediction Horizon')\n",
    "ax[1].set_xticks(np.arange(0,horizon))\n",
    "ax[1].set_xticklabels(horizon_labels)\n",
    "# ax[1].set_ylim(0,20)\n",
    "ax[1].legend()\n",
    "ax[1].set_title('Root Mean Squared Error')\n",
    "\n",
    "# MAPE\n",
    "ax[2].plot(average_error_NoConv[:,2,0], label='MAPE_NoConv', color='gray')\n",
    "ax[2].fill_between(np.arange(horizon), average_error_NoConv[:,2,0] - average_error_NoConv[:,2,1], average_error_NoConv[:,2,0] + average_error_NoConv[:,2,1], alpha=0.2, color='gray')\n",
    "ax[2].plot(average_error_DCRNN[:,2,0], label='MAPE_DCRNN')\n",
    "ax[2].fill_between(np.arange(horizon), average_error_DCRNN[:,2,0] - average_error_DCRNN[:,2,1], average_error_DCRNN[:,2,0] + average_error_DCRNN[:,2,1], alpha=0.3)\n",
    "ax[2].set_ylabel('MAPE')\n",
    "ax[2].set_xlabel('Prediction Horizon')\n",
    "ax[2].set_xticks(np.arange(0,horizon))\n",
    "ax[2].set_xticklabels(horizon_labels)\n",
    "# ax[2].set_ylim(0,50)\n",
    "ax[2].legend()\n",
    "ax[2].set_title('Masked Mean Absolute Percentage Error')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot MAE with standard deviation for selected horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error matrix is of shape (horizon, num_sensors, 6)\n",
    "num_sensors = errorDCRNN.shape[1]\n",
    "mae_values = errorDCRNN[:,:,0]  # MAE values are at index 0\n",
    "mae_std_values = errorDCRNN[:,:,0]  # MAE std values are at index 1\n",
    "\n",
    "future = 7\n",
    "# Plot the MAE values for each sensor for selected horizon:\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "ax.set_title('MAE_DCRNN values for each sensor for horizon ' + str(horizon_labels[future]))\n",
    "ax.set_xlabel('Sensor')\n",
    "ax.set_ylabel('MAE')\n",
    "ax.set_xticks(np.arange(num_sensors))\n",
    "ax.set_xticklabels(native_indices, rotation=90)\n",
    "ax.bar(np.arange(num_sensors), mae_values[future,:], yerr=mae_std_values[future,:], align='center', alpha=0.5, ecolor='black', capsize=10)\n",
    "# ax.set_ylim([0, 0.5])\n",
    "ax.set_xlim([-1, num_sensors])\n",
    "ax.yaxis.grid(True)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot progression of error metrics as a function of the prediction horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new figure with 3 subplots\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 25))\n",
    "\n",
    "# Horizon labels\n",
    "horizon_labels = ['15min', '30min', '45min', '1h', '1h15min', '1h30min', '1h45min', '2h']  # Adjust this list to match your horizon count\n",
    "\n",
    "# Define the color normalization to fit all heatmaps\n",
    "\n",
    "# Range of values using all sets\n",
    "# vmin = min(np.min(mae_values_DCRNN), np.min(rmse_values_DCRNN), np.min(mape_values_DCRNN))\n",
    "# vmax = max(np.max(mae_values_DCRNN), np.max(rmse_values_DCRNN), np.max(mape_values_DCRNN))\n",
    "\n",
    "# Range of values using MAE for one horizon only\n",
    "vmin = np.min(mae_values_DCRNN[:,future])\n",
    "vmax = np.max(mae_values_DCRNN[:,future])\n",
    "\n",
    "norm = colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "norm_mape = colors.Normalize(vmin=vmin/100, vmax=vmax/100)\n",
    "\n",
    "# Create the MAE heatmap\n",
    "sns.heatmap(mae_values_DCRNN, annot=True, fmt=\".1f\", yticklabels=native_indices , xticklabels=horizon_labels, cmap=\"RdYlGn_r\", ax=axs[0], norm=norm, cbar=False)\n",
    "\n",
    "# Configure the MAE plot\n",
    "axs[0].set_title('MAE_DCRNN Heatmap')\n",
    "axs[0].set_xlabel('Horizon')\n",
    "axs[0].set_ylabel('Sensor ID')\n",
    "\n",
    "\n",
    "# Create the RMSE heatmap\n",
    "sns.heatmap(rmse_values_DCRNN, annot=True, fmt=\".1f\", yticklabels=False, xticklabels=horizon_labels, cmap=\"RdYlGn_r\", ax=axs[1], cbar=False)\n",
    "\n",
    "# Configure the RMSE plot\n",
    "axs[1].set_title('RMSE_DCRNN Heatmap')\n",
    "axs[1].set_xlabel('Horizon')\n",
    "\n",
    "\n",
    "\n",
    "# Create the MAPE heatmap\n",
    "# Use format to have percentage sign: fmt=\"%\" or fmt=\".1%\" for 1 decimal and divide by 100: \n",
    "sns.heatmap(mape_values_DCRNN/100, annot=True, fmt=\"0.1%\", yticklabels=False, xticklabels=horizon_labels, cmap=\"RdYlGn_r\", ax=axs[2], cbar=False)\n",
    "\n",
    "# Configure the MAPE plot\n",
    "axs[2].set_title('MAPE_DCRNN Heatmap')\n",
    "axs[2].set_xlabel('Horizon')\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a map of the sensors with the MAE values color-coding for a selected horizon (future) [Nodes a clickable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the sensor locations\n",
    "locations_full = pd.read_csv('data\\sensor_graph\\denhaag_locations_type.csv', index_col='sensor_id')\n",
    "\n",
    "# Extract the locations for the sensors in the dataset (native_indices)\n",
    "locations = locations_full.loc[native_indices]\n",
    "\n",
    "# Add MAE to the locations DataFrame\n",
    "locations['mae'] = errorDCRNN[future,:,0]  # MAE values for horizon 7 are at index [7,:,0]\n",
    "locations['mape'] = errorDCRNN[future,:,4]  # RMSE values for horizon 7 are at index [7,:,1]\n",
    "\n",
    "# Create a map centered at the average location\n",
    "m = folium.Map(location=locations[['latitude', 'longitude']].mean().to_list(), zoom_start=13, tiles='https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}',\n",
    "               attr='Esri')\n",
    "\n",
    "# Create a color map\n",
    "min_mae = locations['mae'].min()\n",
    "max_mae = locations['mae'].max()\n",
    "min_mape = locations['mape'].min()\n",
    "max_mape = locations['mape'].max()\n",
    "cmap = colormaps.get_cmap('RdYlGn_r')  # '_r' indicates a reversed colormap\n",
    "norm = colors.Normalize(vmin=min_mae, vmax=max_mae)\n",
    "norm_mape = colors.Normalize(vmin=min_mape, vmax=max_mape)\n",
    "\n",
    "# Function to map MAE to color\n",
    "def get_color(mae):\n",
    "    return colors.to_hex(cmap(norm(mae)))\n",
    "\n",
    "# Function to map MAPE to color\n",
    "def get_color_mape(mape):\n",
    "    return colors.to_hex(cmap(norm_mape(mape)))\n",
    "\n",
    "# Add markers to the map\n",
    "for idx, row in locations.iterrows():\n",
    "    folium.CircleMarker(location=(row['latitude'], row['longitude']),\n",
    "                        radius=7,\n",
    "                        color=get_color_mape(row['mape']),\n",
    "                        fill=True,\n",
    "                        fill_opacity=1,\n",
    "                        fill_color=get_color(row['mae']),\n",
    "                        popup=folium.Popup(f'Sensor ID: {idx}<br>MAE: {row[\"mae\"]:.1f} (Fill)<br>MAPE: {row[\"mape\"]:.1f} (Stroke)' , max_width=300) # Use f-strings to format the popup, sensor_id is an integer and mae is a float: \n",
    "                       ).add_to(m)\n",
    "\n",
    "# Show the map\n",
    "m"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a heatmap for the differences in performance between the two models and show them on the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_mae = (mae_values_DCRNN - mae_values_NoConv)/mae_values_NoConv\n",
    "delta_rmse = (rmse_values_DCRNN - rmse_values_NoConv)/rmse_values_NoConv\n",
    "delta_mape = (mape_values_DCRNN - mape_values_NoConv)/mape_values_NoConv\n",
    "\n",
    "# Range of values\n",
    "max_delta_mae = np.max(np.abs(delta_mae))\n",
    "max_delta_rmse = np.max(np.abs(delta_rmse))\n",
    "max_delta_mape = np.max(np.abs(delta_mape))\n",
    "\n",
    "min_delta_mae = -max_delta_mae\n",
    "min_delta_rmse = -max_delta_rmse\n",
    "min_delta_mape = -max_delta_mape\n",
    "\n",
    "\n",
    "# Create a new figure with 4 subplots\n",
    "fig, axs = plt.subplots(1, 3, figsize=(16, 25))\n",
    "\n",
    "# Horizon labels\n",
    "horizon_labels = ['15min', '30min', '45min', '1h', '1h15min', '1h30min', '1h45min', '2h']  # Adjust this list to match your horizon count\n",
    "\n",
    "# Create the MAE_NoConv heatmap\n",
    "sns.heatmap(delta_mae, annot=True, fmt=\".1%\", yticklabels=native_indices, xticklabels=horizon_labels, cmap=\"RdYlGn_r\", vmin=min_delta_mae, vmax=max_delta_mae, ax=axs[0], cbar=False)\n",
    "\n",
    "# Configure the RMSE plot\n",
    "axs[0].set_title(r'$\\Delta$MAE')\n",
    "axs[0].set_xlabel('Horizon')\n",
    "axs[0].set_ylabel('Sensor ID')\n",
    "\n",
    "# Create the RMSE heatmap\n",
    "sns.heatmap(delta_rmse, annot=True, fmt=\".1%\", yticklabels=False, xticklabels=horizon_labels, cmap=\"RdYlGn_r\", vmin=min_delta_rmse, vmax=max_delta_rmse, ax=axs[1], cbar=False)\n",
    "\n",
    "# Configure the RMSE plot\n",
    "axs[1].set_title(r'$\\Delta$RMSE')\n",
    "axs[1].set_xlabel('Horizon')\n",
    "\n",
    "# Create the MAPE heatmap\n",
    "sns.heatmap(delta_mape, annot=True, fmt=\".1%\", yticklabels=False, xticklabels=horizon_labels, cmap=\"RdYlGn_r\", vmin=min_delta_mape, vmax=max_delta_mape, ax=axs[2], cbar=False)\n",
    "\n",
    "# Configure the MAPE plot\n",
    "axs[2].set_title(r'$\\Delta$MAPE')\n",
    "axs[2].set_xlabel('Horizon')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the sensor locations\n",
    "locations_full = pd.read_csv('data\\sensor_graph\\denhaag_locations_type.csv', index_col='sensor_id')\n",
    "\n",
    "# Extract the locations for the sensors in the dataset (native_indices)\n",
    "locations = locations_full.loc[native_indices]\n",
    "\n",
    "# Add MAE to the locations DataFrame\n",
    "locations['delta_mae'] = delta_mae[:, future]  # MAE values for horizon 7 are at index [7,:,0]\n",
    "locations['delta_mape'] = delta_mape[:, future]  # MAE values for horizon 7 are at index [7,:,0]\n",
    "\n",
    "# Create a map centered at the average location\n",
    "m = folium.Map(location=locations[['latitude', 'longitude']].mean().to_list(), zoom_start=13, tiles='https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}',\n",
    "               attr='Esri')\n",
    "\n",
    "# Create a color map\n",
    "min_mae = locations['delta_mae'].min()\n",
    "max_mae = locations['delta_mae'].max()\n",
    "min_mape = locations['delta_mape'].min()\n",
    "max_mape = locations['delta_mape'].max()\n",
    "cmap = colormaps.get_cmap('RdYlGn_r')  # '_r' indicates a reversed colormap\n",
    "norm = colors.Normalize(vmin=min_delta_mae, vmax=max_delta_mae)\n",
    "norm_mape = colors.Normalize(vmin=min_delta_mape, vmax=max_delta_mape)\n",
    "\n",
    "# Function to map MAE to color\n",
    "def get_color(mae):\n",
    "    return colors.to_hex(cmap(norm(mae)))\n",
    "\n",
    "# Function to map MAPE to color\n",
    "def get_color_mape(mape):\n",
    "    return colors.to_hex(cmap(norm_mape(mape)))\n",
    "\n",
    "# Add markers to the map\n",
    "for idx, row in locations.iterrows():\n",
    "    folium.CircleMarker(location=(row['latitude'], row['longitude']),\n",
    "                        radius=7,\n",
    "                        color=get_color_mape(row['delta_mape']),\n",
    "                        fill=True,\n",
    "                        fill_opacity=1,\n",
    "                        fill_color=get_color(row['delta_mae']),\n",
    "                        popup=folium.Popup(f'Sensor ID: {idx}<br>Delta MAE: {row[\"delta_mae\"]:.1%} (Fill)<br>Delta MAPE: {row[\"delta_mape\"]:.1%} (Stroke)' , max_width=300) # Use f-strings to format the popup, sensor_id is an integer and mae is a float: \n",
    "                       ).add_to(m)\n",
    "\n",
    "# Show the map\n",
    "m"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Animation: 24-hour window moving across the test set for a selected sensor_ID and horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "native_id = 702112  # Replace this with the native ID of the sensor you want to plot\n",
    "\n",
    "horizon = 8 # horizon to plot\n",
    "\n",
    "step = 2 # in hours between frames\n",
    "\n",
    "window = 24 # in hours\n",
    "\n",
    "\n",
    "#########\n",
    "\n",
    "\n",
    "# Compute the number of frames to plot:\n",
    "num_frames = int((truth.shape[1] - (window*samples_per_hour+4))/(samples_per_hour*step))-1 \n",
    "\n",
    "\n",
    "if native_id in native_indices:\n",
    "    node_index = native_indices.index(native_id)\n",
    "else:\n",
    "    print(f\"Sensor {native_id} not found in native_indices.\")\n",
    "    node_index = None\n",
    "\n",
    "# Calculate the maximum value over all frames, predictions and truth sets\n",
    "max_value = max(np.max(truth[horizon-1, :, node_index]), \n",
    "                np.max(prediction1[horizon-1, :, node_index]),\n",
    "                np.max(prediction2[horizon-1, :, node_index]))\n",
    "# Add a small margin (10% of the max value)\n",
    "max_value *= 1.1\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Function to update the plot for a given hour\n",
    "def update(hour):\n",
    "    start_sample = step*hour * samples_per_hour + 4\n",
    "    end_sample = start_sample + window * samples_per_hour\n",
    "\n",
    "    if node_index is not None:\n",
    "        # prediction_node3 = prediction3[0, start_sample + shift:end_sample + shift, node_index]\n",
    "        prediction_node2 = prediction2[horizon-1, start_sample:end_sample, node_index]\n",
    "        prediction_node1 = prediction1[horizon-1, start_sample:end_sample, node_index]\n",
    "        truth_node = truth[horizon-1, start_sample:end_sample, node_index]\n",
    "\n",
    "        # Clear the current plot\n",
    "        ax.clear()\n",
    "\n",
    "        ax.plot(truth_node, label='Truth', color='tab:orange')\n",
    "        ax.plot(prediction_node1, label='NoConv',color='tab:red')\n",
    "        ax.plot(prediction_node2, label='DCRNN (DR2+RNN2)',color='tab:blue')\n",
    "        # ax.plot(prediction_node3, label='DR2',color='tab:green')   \n",
    "\n",
    "        ax.set_xlabel('Timestamp')\n",
    "        ax.set_ylabel('Number of vehicles')\n",
    "        ax.legend()\n",
    "        ax.set_title(f'Sensor {native_id}')\n",
    "        ax.set_ylim([0, max_value])  # Set the top y-limit to max_value\n",
    "        ax.set_xticks(range(0, len(timestamps[start_sample:end_sample])+1, 2 * samples_per_hour))\n",
    "        ax.set_xticklabels(timestamps_str[start_sample:end_sample+1:2 * samples_per_hour], rotation=0, ha='center')\n",
    "\n",
    "# Create the animation\n",
    "ani = animation.FuncAnimation(fig, update, frames=range(0, num_frames), interval=100)\n",
    "plt.close()\n",
    "# Display the animation\n",
    "HTML(ani.to_jshtml())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Static plot for a single sensor [24 hours - window]\n",
    "\n",
    "# # Select 24-hour window\n",
    "# start_hour = 23  # Change this to select the starting hour of the 3-hour window\n",
    "# start_sample = start_hour * samples_per_hour\n",
    "# end_sample = start_sample + 24 * samples_per_hour\n",
    "\n",
    "# # Select the sensor to display\n",
    "# native_id = 702112\n",
    "\n",
    "# if native_id in native_indices:\n",
    "#     node_index = native_indices.index(native_id)\n",
    "# else:\n",
    "#     print(f\"Sensor {native_id} not found in native_indices.\")\n",
    "#     node_index = None\n",
    "\n",
    "# # Choose the horizon to display\n",
    "# horizon = 8\n",
    "\n",
    "# # prediction_node3 = prediction3[0, start_sample + shift:end_sample + shift, node_index]\n",
    "# prediction_node2 = prediction2[horizon-1, start_sample:end_sample, node_index]\n",
    "# prediction_node1 = prediction1[horizon-1, start_sample:end_sample, node_index]\n",
    "# truth_node = truth[horizon-1, start_sample:end_sample, node_index]\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(12, 6))\n",
    "# ax.plot(truth_node, label='Truth', color='tab:orange')\n",
    "# ax.plot(prediction_node1, label='NoConv',color='tab:red')\n",
    "# ax.plot(prediction_node2, label='DCRNN (DR2+RNN2)',color='tab:blue')\n",
    "\n",
    "# ax.set_xlabel('Timestamp')\n",
    "# ax.set_ylabel('Number of vehicles')\n",
    "# ax.legend()\n",
    "# ax.set_title(f'Sensor {native_indices[node_index]}')\n",
    "# ax.set_xticks(range(0, len(timestamps[start_sample:end_sample])+1, 2 * samples_per_hour))\n",
    "# ax.set_xticklabels(timestamps_str[start_sample:end_sample+1:2 * samples_per_hour], rotation=0, ha='center')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Static plot predictions for all sensors (123 subplots) [24 hours windows]\n",
    "\n",
    "# # Select 24-hour window\n",
    "# day = 0  # Change this to select the starting day of the 24-hour window\n",
    "\n",
    "# start_hour = 24*day  # Change this to select the starting hour of the 24-hour window\n",
    "# start_sample = start_hour * samples_per_hour\n",
    "# end_sample = start_sample + 24 * samples_per_hour\n",
    "\n",
    "# fig, axs = plt.subplots(62, 2, figsize=(20, 400))\n",
    "# fig.tight_layout(pad=5.0)\n",
    "\n",
    "\n",
    "# for i, native_index in enumerate(native_indices):\n",
    "#     row = i // 2\n",
    "#     col = i % 2\n",
    "\n",
    "#     prediction_node2 = prediction2[0, start_sample:end_sample, i]\n",
    "#     prediction_node1 = prediction1[0, start_sample:end_sample, i]\n",
    "#     truth_node = truth[0, start_sample:end_sample, i]\n",
    "\n",
    "#     axs[row, col].plot(truth_node, label='Truth', color='tab:orange')    \n",
    "#     axs[row, col].plot(prediction_node1, label='DR0',color='tab:red')\n",
    "#     axs[row, col].plot(prediction_node2, label='DR1',color='tab:blue')\n",
    "\n",
    "\n",
    "#     axs[row, col].set_xlabel('Timestamp')\n",
    "#     axs[row, col].set_ylabel('Number of vehicles')\n",
    "#     axs[row, col].legend()\n",
    "#     axs[row, col].set_title(f'Sensor {native_index}')\n",
    "#     axs[row, col].set_xticks(range(0, len(timestamps[start_sample:end_sample+1]), 2*samples_per_hour))\n",
    "#     axs[row, col].set_xticklabels(timestamps_str[start_sample:end_sample+1:2*samples_per_hour], rotation=0, ha='center')\n",
    "\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
